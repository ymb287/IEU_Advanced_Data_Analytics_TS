---
title: "Advanced Data Analytics"
author:
  - Loukas Gonzalez
  - Simon Alvarez Bliffeld
  - Simon Gonzalez
  - Yannik Biebert
date: "2023-11-28"
output:      
  rmarkdown::html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
---

```{r setup, include=FALSE}
# Set up: do not change!!!
knitr::opts_chunk$set(echo = TRUE)
```

<br>

------------------------------------------------------------------------

<br>

# Part 1: Prepare and inspect the data

Steps for us:

- Visual inspection of data DONE

- Homoscedasticity testing DONE

- Inspect autocorrelation with acf and pacf DONE

- Inspect volatility clustering (if so, maybe GARCH needed?)

- Inspect trend and seasonality with zoom in or decompose and if it has use holt-winters, DO WE NEED TBATS or STLM? Because I dont think whe have two cicles in each other

- Maybe new autocorrelation with acf and pacf for the estimated seansonality and trend (if we use the holt winter model to mode arima)

- Look for ARIMA models (on data and on estimated ets()/msts()

- Compare models (including ets models)

- Choose best model and visualize, look at residuals, maybe GARCH (or should be aready dicide this before using ARIMA Model and use it directly?)

- Use maybe Garch, and compare those models

- Summary of findings

- Forcast and plot final model

- conclusion of forecast

------------------------------------------------------------------------

## 1.1 Importing and inspecting the data set

```{r Import data, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# import packages
library(pacman)
p_load(
  readxl, tseries, tidyverse, dplyr, tidyr, forecast, fpp2, stats, quantmod
)

# import data set xlxs
data <- read_excel("Datasets.xlsx")

# removing not used columns Housing and Unemployment
data <- data[, -c(7, 9)]


# Display the data set
print(data)

```

## 1.2 Prepare the data

```{r transform data, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Split the data into two dataframes based on the country
data_italy <- subset(data, Country %in% c("Italy"))
data_usa <- subset(data, Country %in% c("USA"))

# Function for data transformation
transform_data <- function(df) {
  # Extract columns from the dataframe
  gdp <- df$'GDP, billion currency units'
  cpi <- df$'Consumer Price Index (CPI)'
  stocks <- df$'Stock market index'

  # Drop missing values (becuase only every quarter)
  gdp <- na.omit(gdp)

  # Drop missing values (becuase last in the month)
  cpi <- na.omit(cpi)
  stocks <- na.omit(stocks)

  # Change to time series
  gdp <- ts(gdp, start = c(2000, 1), frequency = 4)
  cpi <- ts(cpi, start = c(2000, 1), frequency = 12)
  stocks <- ts(stocks, start = c(2000, 1), frequency = 12)
  
  # Return the time series as separate variables
  return(list(gdp = gdp, cpi = cpi, stocks = stocks))
}

# Apply the transformation function
transformed_italy  <- transform_data(data_italy)
transformed_usa <- transform_data(data_usa)

```

```{r plot the data italy, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Plot the Italy data
plot(transformed_italy$gdp, main = "GDP in Italy"
     , xlab = "Year", ylab = "GDP")
plot(transformed_italy$cpi, main = "CPI in Italy"
     , xlab = "Year", ylab = "CPI")
plot(transformed_italy$stocks, main = "Stocks in Italy"
     , xlab = "Year", ylab = "Stocks")


# TODO Use different boxes, so we can do an interpretation after each plot

```

```{r plot the data usa, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Plot the USA data
plot(transformed_usa$gdp, main = "GDP in USA"
     , xlab = "Year", ylab = "GDP")
plot(transformed_usa$cpi, main = "CPI in USA"
     , xlab = "Year", ylab = "CPI")
plot(transformed_usa$stocks, main = "Stocks in USA"
     , xlab = "Year", ylab = "Stocks")

# TODO Use different boxes, so we can do an interpretation after each plot


```

TODO Looking into seasonality

## 1.3 Evaluate the data from Italy

```{r evaluate data italy, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Analyse the different variables for stationarity
analyze_time_series <- function(ts_data, country) {
  # Set up the plot
  par(mfrow = c(2, 2))

  # Loop through the variables in the list
  for (i in seq_along(names(ts_data))) {
    variable <- names(ts_data)[i]
    
    # Doing the ADF and PP test, as well as determining diff
    adf_result <- adf.test(ts_data[[variable]])
    pp_result <- pp.test(ts_data[[variable]])
    num_diffs <- ndiffs(ts_data[[variable]])

    # Print results for the current variable
    cat("Results for", variable, "in", country, ":\n")
    cat("ADF Test:\n")
    cat("  P-Value:", adf_result$p.value, "\n")
    cat("PP Test:\n")
    cat("  P-Value:", pp_result$p.value, "\n")
    cat("Number of Differences Required for Stationarity:", num_diffs, "\n\n")

    # ACF and PACF plots
    acf(ts_data[[variable]], main = paste("ACF of", variable, "in", country))
    pacf(ts_data[[variable]], main = paste("PACF of", variable, "in", country))
    
    # If we have processed the first two variables, reset layout for the next row
    if (i == 2) {
      par(mfrow = c(2, 2))
    }
  }
}

# Explore data of Italy
analyze_time_series(transformed_italy, "Italy")


# TODO Seperate the code to do an interpretation after every part

```

Non of the variables is stationary. We will have to difference them.

```{r evaluate differenced italy, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Analyse the differenced variables for stationary
analyze_diff_series <- function(ts_data, country) {
  # Loop through the variables in the list
  for (variable in names(ts_data)) {
    # Getting number of differences required for stationarity
    ts <- ts_data[[variable]]
    num_diffs <- ndiffs(ts)
    
    # Differncing num_diffs times
    for (i in 1:num_diffs) {
      ts <- diff(ts)
    }
    
    # Performing the ADF and PP test
    adf_result <- adf.test(ts)
    pp_result <- pp.test(ts)
    num_diffs_new <- ndiffs(ts)
    
    # Print results for the current variable
    cat("Results for", variable, "in", country, ":\n")
    cat("ADF Test:\n")
    cat("  P-Value:", adf_result$p.value, "\n")
    cat("PP Test:\n")
    cat("  P-Value:", pp_result$p.value, "\n")
    cat("Number of Differences Required for Stationarity:", num_diffs_new, "\n\n")
  }
}

# Difference data from Italy
analyze_diff_series(transformed_italy, "Italy")

```

All good its stationary

## 1.4 Evaluate the data from the USA

```{r evaluate data usa, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Explore data of USA
analyze_time_series(transformed_italy, "USA")

```


```{r evaluate differenced usa, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Difference data from USA
analyze_diff_series(transformed_italy, "Italy")

```
All good its stationary


## 1.5 Train test split

```{r train test split, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Creang train test split function
train_test_split <- function(data_list, train_percentage = 0.8) {
  split_data <- list()
  
  # Loop through the variables in the list
  for (variable in names(data_list)) {
    ts_data <- data_list[[variable]]
    data_length <- length(ts_data)

    # Calculate the train size
    train_size <- round(train_percentage * data_length)

    # Split the data
    train_data <- ts_data[1:train_size]
    test_data <- ts_data[(train_size + 1):data_length]
    
    # Add the data to the list
    split_data[[paste0(variable, "_train")]] <- train_data
    split_data[[paste0(variable, "_test")]] <- test_data
  }

  return(split_data)
}

# Apply the train test split function
split_italy <- train_test_split(transformed_italy)
split_usa <- train_test_split(transformed_usa)

print(is.ts(split_italy$gdp_train)) # TODO IS NOT A TS ANYMORE SHE DID NOT CARE EITHER?
print(split_italy$gdp_train) 


```

Had for some reason huge troubles with it sting in ts so needed to create this

```{r train test split alternative, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# TODO Do we want to use this or the one above?

# Function for train test split
train_test_split <- function(data_list, train_percentage = 0.8) {
  split_data <- list()
  
  # Loop through the variables in the list
  for (variable in names(data_list)) {
    ts_data <- data_list[[variable]]
    data_length <- length(ts_data)

    # Calculate the train size
    train_size <- round(train_percentage * data_length)
    
    # Train split, this way needed, to keep the ts format
    train_data <- ts(ts_data[1:train_size], start = start(ts_data), frequency = frequency(ts_data))

    end_time <- time(train_data)[length(train_data)]
    
    # Get start for testdata, if only split with [:] the ts type is lost as well as the start time
    if (frequency(ts_data) == 12) {
      end_time <- end_time + 1/12
      start_year <- floor(end_time)
      start_month <- (end_time - start_year) * 12 + 1
    } else if (frequency(ts_data) == 4) {
      end_time <- end_time + 1/4
      start_year <- floor(end_time)
      start_month <- (end_time - start_year) * 4 + 1
    } else {
      print('Error: Frequency not supported')
    }

    test_data <- ts(ts_data[(train_size + 1):data_length], start = c(start_year, start_month), frequency = frequency(ts_data))
    
    # Add the data to the list
    split_data[[paste0(variable, "_train")]] <- train_data
    split_data[[paste0(variable, "_test")]] <- test_data
  }

  return(split_data)
}

# Apply the train test split function
split_italy <- train_test_split(transformed_italy)
split_usa <- train_test_split(transformed_usa)

```



```{r extract data, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

# Italy variables
gdp_italy_train <- split_italy$gdp_train
gdp_italy_test <- split_italy$gdp_test

cpi_italy_train <- split_italy$cpi_train
cpi_italy_test <- split_italy$cpi_test

stocks_italy_train <- split_italy$stocks_train
stocks_italy_test <- split_italy$stocks_test

# USA variables
gdp_usa_train <- split_usa$gdp_train
gdp_usa_test <- split_usa$gdp_test

cpi_usa_train <- split_usa$cpi_train
cpi_usa_test <- split_usa$cpi_test

stocks_usa_train <- split_usa$stocks_train
stocks_usa_test <- split_usa$stocks_test

```


<br>

------------------------------------------------------------------------

<br>

# Part 2: Model Itally


------------------------------------------------------------------------

<br>

## 2 GDP

```{r modelling italy gdp, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Function for model creation
ntest <- length(gdp_italy_test)

# TODO in text : ACF slow decay, PACF sharp, probably AR 
# 16 MA
# Diff 1
# 9 AR

model_max <- Arima(gdp_italy_train, order = c(9, 1, 16), method = "ML")
model_aic <- auto.arima(gdp_italy_train, ic = 'aic')
model_bic <- auto.arima(gdp_italy_train, ic = 'bic')

predict_max <- forecast::forecast(model_max, h = ntest, level = 0)
predict_aic <- forecast::forecast(model_aic, h = ntest, level = 0)
predict_bic <- forecast::forecast(model_bic, h = ntest, level = 0)

# Get the AIC 

################## HAVE TO WORK WITH cat()

model_max$aic
model_aic$aic
model_bic$aic

print(' ')

accuracy(predict_max, gdp_italy_test)
accuracy(predict_aic, gdp_italy_test)
accuracy(predict_bic, gdp_italy_test)

# Two best:
model_aic # WHAT IS SMA1?
model_bic


# Box.test(auto_model_adjusted_bic$residuals) # p-value = 0.01 --> Residuals NOT white noise
                                            # Big p is only white noise


```


```{r}

### plot the forecasts

# elp$pred <- c(model$fitted, pred$mean)

# ggplot(elp)+ 
#   geom_line(aes(mdy(DATE), Value, group = 1))+
#   geom_line(aes(mdy(DATE), pred, group = 1), color = "dodgerblue4")+
#   geom_vline(aes(xintercept=mdy("02-01-2016")), color = "darkorange2", size = 0.9)+
#   xlab("Date")+
#   ylab("Electric production")

### zoom into the test set

# ggplot(elp[374:397,])+
#   geom_line(aes(mdy(DATE), Value, group = 1))+
#   geom_line(aes(mdy(DATE), pred, group = 1), color = "dodgerblue4")+
#   xlab("Date")+
#   ylab("Electric production")


```




